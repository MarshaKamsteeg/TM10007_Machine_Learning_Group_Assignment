{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tm10007_group_9_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaKamsteeg/TM10007_Machine_Learning_Group_Assignment/blob/main/tm10007_group_9_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CiDn2Sk-VWqE",
        "outputId": "c0e185d9-bfd4-468e-8fcc-7bda037eadc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYv2pEkF8Eg"
      },
      "source": [
        "## Description of data set\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-NE_fTbKGe5z",
        "outputId": "12096774-1d31-4c72-fa38-814c5fdfd153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 855\n",
            "Total number of columns: 268\n",
            "Total amount of features: 266\n",
            "There are no empty values found.\n",
            "Within the dataset 519 samples are from people with Alzheimer Disease\n",
            "The other 336 samples are from people without Alzheimer Disease\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
          ]
        }
      ],
      "source": [
        "# Import Data\n",
        "from adni.load_data import load_data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import Data\n",
        "data = load_data()\n",
        "data_pandas = pd.DataFrame(data)\n",
        "print(f'Total number of samples: {len(data.index)}')\n",
        "print(f'Total number of columns: {len(data.columns)}')\n",
        "print(f'Total amount of features: {len(data.columns)-2}')\n",
        "\n",
        "# Find empty / NaN entry in pandas dataframe\n",
        "data_pandas = data_pandas.replace(' ', np.nan) \n",
        "empty_values = np.where(pd.isnull(data_pandas))\n",
        "\n",
        "if ~empty_values[0] == []:\n",
        "  print(f'Empty values can be found at index {empty_values}')\n",
        "else:\n",
        "  print('There are no empty values found.')\n",
        "  pass\n",
        "\n",
        "# Percentage AD and CN\n",
        "number_AD = data_pandas['label'].value_counts()['AD']\n",
        "number_CN = data_pandas['label'].value_counts()['CN']\n",
        "print(f\"Within the dataset {number_AD} samples are from people with Alzheimer Disease\")\n",
        "print(f\"The other {number_CN} samples are from people without Alzheimer Disease\") \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing of the data"
      ],
      "metadata": {
        "id": "ZQTiKJ50EHlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dividing data in a designgset (80%) and testset (20%)"
      ],
      "metadata": {
        "id": "fTizaTtFMVOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide data in label and feature set \n",
        "labels = data['label']\n",
        "features = data.drop(columns=['label'])\n",
        "\n",
        "# Divide data in trainingsset (80%) and testset (20%) stratified for the label\n",
        "data_designset, data_testset, label_designset, label_testset = train_test_split(features, labels, test_size=.2, random_state=1, stratify=data['label'])\n",
        "\n",
        "# Check the stratification \n",
        "percent_AD_train = (label_designset.value_counts()['AD'])/len(label_designset)*100\n",
        "percent_CN_train = (label_designset.value_counts()['CN'])/len(label_designset)*100\n",
        "percent_AD_test = (label_testset.value_counts()['AD'])/len(label_testset)*100\n",
        "percent_CN_test = (label_testset.value_counts()['CN'])/len(label_testset)*100\n",
        "\n",
        "print(f\"{percent_AD_train:.2f}% of the train data are Alzheimer disease samples.\")\n",
        "print(f\"{percent_CN_train:.2f}% of the train data are control samples.\")\n",
        "print(f\"{percent_AD_test:.2f}% of the test data are Alzheimer disease samples.\")\n",
        "print(f\"{percent_CN_test:.2f}% of the test data are control samples.\")\n"
      ],
      "metadata": {
        "id": "D-_lSnqzDCao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e8912e-d268-464c-c188-997a637a138e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60.67% of the train data are Alzheimer disease samples.\n",
            "39.33% of the train data are control samples.\n",
            "60.82% of the test data are Alzheimer disease samples.\n",
            "39.18% of the test data are control samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Dropping"
      ],
      "metadata": {
        "id": "5Cle-UrdMhyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find columns where >90% of the column has value zero. Remove this feature if this is true\n",
        "data_designset.drop(columns=data_designset.columns[data_designset.eq(0).mean()>0.9])"
      ],
      "metadata": {
        "id": "5vKxdt1OYemg",
        "outputId": "e5a8245d-f0ec-4586-c010-2243d95e756f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      hf_energy  hf_entropy  hf_kurtosis    hf_max   hf_mean  \\\n",
              "ID                                                                             \n",
              "0_016_S_4009_bl_0    620.338163    5.128957    -0.135256  1.231229  0.644556   \n",
              "0_141_S_0767_bl_0    921.747797    4.448338     3.140272  1.566359  1.052297   \n",
              "0_018_S_4349_bl_0  15722.331725    4.354226     3.090342  2.313908  1.753796   \n",
              "0_127_S_4940_bl_0   1566.455496    5.175812    -1.474096  1.551087  0.632457   \n",
              "0_011_S_0021_bl_0   1396.801137    4.310042     4.281509  1.639478  1.133137   \n",
              "...                         ...         ...          ...       ...       ...   \n",
              "0_009_S_0842_bl_0   3757.368887    4.508431     4.883810  2.129794  1.444995   \n",
              "0_100_S_5075_bl_0  12942.678777    4.426823     3.389407  2.250390  1.774349   \n",
              "0_070_S_4719_bl_0   1607.410337    4.862292    -0.113694  1.596243  0.961981   \n",
              "0_002_S_0685_bl_0   3443.797200    4.613089     3.404878  1.775424  1.236849   \n",
              "0_100_S_0743_bl_0   1412.371885    5.210843    -1.529035  1.422504  0.515638   \n",
              "\n",
              "                   hf_median    hf_min  hf_peak  hf_quartile_range  hf_range  \\\n",
              "ID                                                                             \n",
              "0_016_S_4009_bl_0   0.745517 -0.260302      204           0.479143  1.491532   \n",
              "0_141_S_0767_bl_0   1.080785  0.209751      179           0.295765  1.356608   \n",
              "0_018_S_4349_bl_0   1.749090  1.072839      364           0.260229  1.241069   \n",
              "0_127_S_4940_bl_0   0.729728 -0.280274      208           1.170020  1.831361   \n",
              "0_011_S_0021_bl_0   1.132616  0.575885      243           0.275302  1.063593   \n",
              "...                      ...       ...      ...                ...       ...   \n",
              "0_009_S_0842_bl_0   1.502802 -0.076841      434           0.369507  2.206635   \n",
              "0_100_S_5075_bl_0   1.816222  0.936545      317           0.261290  1.313845   \n",
              "0_070_S_4719_bl_0   1.131252 -0.151707      290           0.609169  1.747950   \n",
              "0_002_S_0685_bl_0   1.308478  0.062127      419           0.311673  1.713297   \n",
              "0_100_S_0743_bl_0   0.583915 -0.398832      200           1.217663  1.821336   \n",
              "\n",
              "                   ...  vf_Frangi_inner_kurtosis_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                 ...                                                 \n",
              "0_016_S_4009_bl_0  ...                                      4.508531   \n",
              "0_141_S_0767_bl_0  ...                                     -3.000000   \n",
              "0_018_S_4349_bl_0  ...                                     -1.500000   \n",
              "0_127_S_4940_bl_0  ...                                      0.439466   \n",
              "0_011_S_0021_bl_0  ...                                     -3.000000   \n",
              "...                ...                                           ...   \n",
              "0_009_S_0842_bl_0  ...                                      1.266101   \n",
              "0_100_S_5075_bl_0  ...                                     -3.000000   \n",
              "0_070_S_4719_bl_0  ...                                      0.866371   \n",
              "0_002_S_0685_bl_0  ...                                      0.678418   \n",
              "0_100_S_0743_bl_0  ...                                      1.879230   \n",
              "\n",
              "                   vf_Frangi_inner_max_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                           \n",
              "0_016_S_4009_bl_0                             1.300122e-09   \n",
              "0_141_S_0767_bl_0                             0.000000e+00   \n",
              "0_018_S_4349_bl_0                             1.987360e-10   \n",
              "0_127_S_4940_bl_0                             4.473136e-09   \n",
              "0_011_S_0021_bl_0                             4.839984e-14   \n",
              "...                                                    ...   \n",
              "0_009_S_0842_bl_0                             1.265295e-09   \n",
              "0_100_S_5075_bl_0                             0.000000e+00   \n",
              "0_070_S_4719_bl_0                             1.941420e-10   \n",
              "0_002_S_0685_bl_0                             1.853995e-10   \n",
              "0_100_S_0743_bl_0                             1.276717e-09   \n",
              "\n",
              "                   vf_Frangi_inner_mean_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                            \n",
              "0_016_S_4009_bl_0                              4.311395e-10   \n",
              "0_141_S_0767_bl_0                              0.000000e+00   \n",
              "0_018_S_4349_bl_0                              1.478404e-10   \n",
              "0_127_S_4940_bl_0                              1.307038e-09   \n",
              "0_011_S_0021_bl_0                              4.839984e-14   \n",
              "...                                                     ...   \n",
              "0_009_S_0842_bl_0                              3.796334e-10   \n",
              "0_100_S_5075_bl_0                              0.000000e+00   \n",
              "0_070_S_4719_bl_0                              5.489328e-11   \n",
              "0_002_S_0685_bl_0                              4.602008e-11   \n",
              "0_100_S_0743_bl_0                              3.958873e-10   \n",
              "\n",
              "                   vf_Frangi_inner_median_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                              \n",
              "0_016_S_4009_bl_0                                3.479244e-10   \n",
              "0_141_S_0767_bl_0                                0.000000e+00   \n",
              "0_018_S_4349_bl_0                                1.602012e-10   \n",
              "0_127_S_4940_bl_0                                8.259568e-10   \n",
              "0_011_S_0021_bl_0                                4.839984e-14   \n",
              "...                                                       ...   \n",
              "0_009_S_0842_bl_0                                3.352694e-10   \n",
              "0_100_S_5075_bl_0                                0.000000e+00   \n",
              "0_070_S_4719_bl_0                                3.371375e-11   \n",
              "0_002_S_0685_bl_0                                1.540497e-11   \n",
              "0_100_S_0743_bl_0                                2.411036e-10   \n",
              "\n",
              "                   vf_Frangi_inner_min_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                           \n",
              "0_016_S_4009_bl_0                             1.539406e-10   \n",
              "0_141_S_0767_bl_0                             0.000000e+00   \n",
              "0_018_S_4349_bl_0                             8.606723e-11   \n",
              "0_127_S_4940_bl_0                             8.706174e-11   \n",
              "0_011_S_0021_bl_0                             4.839984e-14   \n",
              "...                                                    ...   \n",
              "0_009_S_0842_bl_0                             3.160450e-11   \n",
              "0_100_S_5075_bl_0                             0.000000e+00   \n",
              "0_070_S_4719_bl_0                             3.614827e-14   \n",
              "0_002_S_0685_bl_0                             3.387661e-13   \n",
              "0_100_S_0743_bl_0                             3.669396e-11   \n",
              "\n",
              "                   vf_Frangi_inner_peak_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                            \n",
              "0_016_S_4009_bl_0                                         7   \n",
              "0_141_S_0767_bl_0                                         1   \n",
              "0_018_S_4349_bl_0                                         1   \n",
              "0_127_S_4940_bl_0                                        27   \n",
              "0_011_S_0021_bl_0                                         1   \n",
              "...                                                     ...   \n",
              "0_009_S_0842_bl_0                                        14   \n",
              "0_100_S_5075_bl_0                                         1   \n",
              "0_070_S_4719_bl_0                                         2   \n",
              "0_002_S_0685_bl_0                                         4   \n",
              "0_100_S_0743_bl_0                                        12   \n",
              "\n",
              "                   vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                                      \n",
              "0_016_S_4009_bl_0                                       2.356782e-10    \n",
              "0_141_S_0767_bl_0                                       0.000000e+00    \n",
              "0_018_S_4349_bl_0                                       5.868167e-11    \n",
              "0_127_S_4940_bl_0                                       1.505578e-09    \n",
              "0_011_S_0021_bl_0                                       0.000000e+00    \n",
              "...                                                              ...    \n",
              "0_009_S_0842_bl_0                                       3.722508e-10    \n",
              "0_100_S_5075_bl_0                                       0.000000e+00    \n",
              "0_070_S_4719_bl_0                                       6.423807e-11    \n",
              "0_002_S_0685_bl_0                                       5.488386e-11    \n",
              "0_100_S_0743_bl_0                                       5.085240e-10    \n",
              "\n",
              "                   vf_Frangi_inner_range_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                             \n",
              "0_016_S_4009_bl_0                               1.146181e-09   \n",
              "0_141_S_0767_bl_0                               0.000000e+00   \n",
              "0_018_S_4349_bl_0                               1.126688e-10   \n",
              "0_127_S_4940_bl_0                               4.386074e-09   \n",
              "0_011_S_0021_bl_0                               0.000000e+00   \n",
              "...                                                      ...   \n",
              "0_009_S_0842_bl_0                               1.233690e-09   \n",
              "0_100_S_5075_bl_0                               0.000000e+00   \n",
              "0_070_S_4719_bl_0                               1.941059e-10   \n",
              "0_002_S_0685_bl_0                               1.850608e-10   \n",
              "0_100_S_0743_bl_0                               1.240023e-09   \n",
              "\n",
              "                   vf_Frangi_inner_skewness_SR(1.0, 10.0)_SS2.0  \\\n",
              "ID                                                                \n",
              "0_016_S_4009_bl_0                                      2.063715   \n",
              "0_141_S_0767_bl_0                                      0.000000   \n",
              "0_018_S_4349_bl_0                                     -0.364345   \n",
              "0_127_S_4940_bl_0                                      1.204938   \n",
              "0_011_S_0021_bl_0                                      0.000000   \n",
              "...                                                         ...   \n",
              "0_009_S_0842_bl_0                                      1.185341   \n",
              "0_100_S_5075_bl_0                                      0.000000   \n",
              "0_070_S_4719_bl_0                                      1.408913   \n",
              "0_002_S_0685_bl_0                                      1.427118   \n",
              "0_100_S_0743_bl_0                                      1.439770   \n",
              "\n",
              "                   vf_Frangi_inner_std_SR(1.0, 10.0)_SS2.0  \n",
              "ID                                                          \n",
              "0_016_S_4009_bl_0                             3.011985e-10  \n",
              "0_141_S_0767_bl_0                             0.000000e+00  \n",
              "0_018_S_4349_bl_0                             4.870408e-11  \n",
              "0_127_S_4940_bl_0                             1.249381e-09  \n",
              "0_011_S_0021_bl_0                             0.000000e+00  \n",
              "...                                                    ...  \n",
              "0_009_S_0842_bl_0                             2.881653e-10  \n",
              "0_100_S_5075_bl_0                             0.000000e+00  \n",
              "0_070_S_4719_bl_0                             6.653018e-11  \n",
              "0_002_S_0685_bl_0                             5.954654e-11  \n",
              "0_100_S_0743_bl_0                             3.400361e-10  \n",
              "\n",
              "[684 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed64f1f8-a143-42f5-8e34-17990bba8a38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hf_energy</th>\n",
              "      <th>hf_entropy</th>\n",
              "      <th>hf_kurtosis</th>\n",
              "      <th>hf_max</th>\n",
              "      <th>hf_mean</th>\n",
              "      <th>hf_median</th>\n",
              "      <th>hf_min</th>\n",
              "      <th>hf_peak</th>\n",
              "      <th>hf_quartile_range</th>\n",
              "      <th>hf_range</th>\n",
              "      <th>...</th>\n",
              "      <th>vf_Frangi_inner_kurtosis_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_max_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_mean_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_median_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_min_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_peak_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_range_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_skewness_SR(1.0, 10.0)_SS2.0</th>\n",
              "      <th>vf_Frangi_inner_std_SR(1.0, 10.0)_SS2.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_016_S_4009_bl_0</th>\n",
              "      <td>620.338163</td>\n",
              "      <td>5.128957</td>\n",
              "      <td>-0.135256</td>\n",
              "      <td>1.231229</td>\n",
              "      <td>0.644556</td>\n",
              "      <td>0.745517</td>\n",
              "      <td>-0.260302</td>\n",
              "      <td>204</td>\n",
              "      <td>0.479143</td>\n",
              "      <td>1.491532</td>\n",
              "      <td>...</td>\n",
              "      <td>4.508531</td>\n",
              "      <td>1.300122e-09</td>\n",
              "      <td>4.311395e-10</td>\n",
              "      <td>3.479244e-10</td>\n",
              "      <td>1.539406e-10</td>\n",
              "      <td>7</td>\n",
              "      <td>2.356782e-10</td>\n",
              "      <td>1.146181e-09</td>\n",
              "      <td>2.063715</td>\n",
              "      <td>3.011985e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_141_S_0767_bl_0</th>\n",
              "      <td>921.747797</td>\n",
              "      <td>4.448338</td>\n",
              "      <td>3.140272</td>\n",
              "      <td>1.566359</td>\n",
              "      <td>1.052297</td>\n",
              "      <td>1.080785</td>\n",
              "      <td>0.209751</td>\n",
              "      <td>179</td>\n",
              "      <td>0.295765</td>\n",
              "      <td>1.356608</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_018_S_4349_bl_0</th>\n",
              "      <td>15722.331725</td>\n",
              "      <td>4.354226</td>\n",
              "      <td>3.090342</td>\n",
              "      <td>2.313908</td>\n",
              "      <td>1.753796</td>\n",
              "      <td>1.749090</td>\n",
              "      <td>1.072839</td>\n",
              "      <td>364</td>\n",
              "      <td>0.260229</td>\n",
              "      <td>1.241069</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>1.987360e-10</td>\n",
              "      <td>1.478404e-10</td>\n",
              "      <td>1.602012e-10</td>\n",
              "      <td>8.606723e-11</td>\n",
              "      <td>1</td>\n",
              "      <td>5.868167e-11</td>\n",
              "      <td>1.126688e-10</td>\n",
              "      <td>-0.364345</td>\n",
              "      <td>4.870408e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_127_S_4940_bl_0</th>\n",
              "      <td>1566.455496</td>\n",
              "      <td>5.175812</td>\n",
              "      <td>-1.474096</td>\n",
              "      <td>1.551087</td>\n",
              "      <td>0.632457</td>\n",
              "      <td>0.729728</td>\n",
              "      <td>-0.280274</td>\n",
              "      <td>208</td>\n",
              "      <td>1.170020</td>\n",
              "      <td>1.831361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.439466</td>\n",
              "      <td>4.473136e-09</td>\n",
              "      <td>1.307038e-09</td>\n",
              "      <td>8.259568e-10</td>\n",
              "      <td>8.706174e-11</td>\n",
              "      <td>27</td>\n",
              "      <td>1.505578e-09</td>\n",
              "      <td>4.386074e-09</td>\n",
              "      <td>1.204938</td>\n",
              "      <td>1.249381e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_011_S_0021_bl_0</th>\n",
              "      <td>1396.801137</td>\n",
              "      <td>4.310042</td>\n",
              "      <td>4.281509</td>\n",
              "      <td>1.639478</td>\n",
              "      <td>1.133137</td>\n",
              "      <td>1.132616</td>\n",
              "      <td>0.575885</td>\n",
              "      <td>243</td>\n",
              "      <td>0.275302</td>\n",
              "      <td>1.063593</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>4.839984e-14</td>\n",
              "      <td>4.839984e-14</td>\n",
              "      <td>4.839984e-14</td>\n",
              "      <td>4.839984e-14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_009_S_0842_bl_0</th>\n",
              "      <td>3757.368887</td>\n",
              "      <td>4.508431</td>\n",
              "      <td>4.883810</td>\n",
              "      <td>2.129794</td>\n",
              "      <td>1.444995</td>\n",
              "      <td>1.502802</td>\n",
              "      <td>-0.076841</td>\n",
              "      <td>434</td>\n",
              "      <td>0.369507</td>\n",
              "      <td>2.206635</td>\n",
              "      <td>...</td>\n",
              "      <td>1.266101</td>\n",
              "      <td>1.265295e-09</td>\n",
              "      <td>3.796334e-10</td>\n",
              "      <td>3.352694e-10</td>\n",
              "      <td>3.160450e-11</td>\n",
              "      <td>14</td>\n",
              "      <td>3.722508e-10</td>\n",
              "      <td>1.233690e-09</td>\n",
              "      <td>1.185341</td>\n",
              "      <td>2.881653e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_100_S_5075_bl_0</th>\n",
              "      <td>12942.678777</td>\n",
              "      <td>4.426823</td>\n",
              "      <td>3.389407</td>\n",
              "      <td>2.250390</td>\n",
              "      <td>1.774349</td>\n",
              "      <td>1.816222</td>\n",
              "      <td>0.936545</td>\n",
              "      <td>317</td>\n",
              "      <td>0.261290</td>\n",
              "      <td>1.313845</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_070_S_4719_bl_0</th>\n",
              "      <td>1607.410337</td>\n",
              "      <td>4.862292</td>\n",
              "      <td>-0.113694</td>\n",
              "      <td>1.596243</td>\n",
              "      <td>0.961981</td>\n",
              "      <td>1.131252</td>\n",
              "      <td>-0.151707</td>\n",
              "      <td>290</td>\n",
              "      <td>0.609169</td>\n",
              "      <td>1.747950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.866371</td>\n",
              "      <td>1.941420e-10</td>\n",
              "      <td>5.489328e-11</td>\n",
              "      <td>3.371375e-11</td>\n",
              "      <td>3.614827e-14</td>\n",
              "      <td>2</td>\n",
              "      <td>6.423807e-11</td>\n",
              "      <td>1.941059e-10</td>\n",
              "      <td>1.408913</td>\n",
              "      <td>6.653018e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_002_S_0685_bl_0</th>\n",
              "      <td>3443.797200</td>\n",
              "      <td>4.613089</td>\n",
              "      <td>3.404878</td>\n",
              "      <td>1.775424</td>\n",
              "      <td>1.236849</td>\n",
              "      <td>1.308478</td>\n",
              "      <td>0.062127</td>\n",
              "      <td>419</td>\n",
              "      <td>0.311673</td>\n",
              "      <td>1.713297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.678418</td>\n",
              "      <td>1.853995e-10</td>\n",
              "      <td>4.602008e-11</td>\n",
              "      <td>1.540497e-11</td>\n",
              "      <td>3.387661e-13</td>\n",
              "      <td>4</td>\n",
              "      <td>5.488386e-11</td>\n",
              "      <td>1.850608e-10</td>\n",
              "      <td>1.427118</td>\n",
              "      <td>5.954654e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0_100_S_0743_bl_0</th>\n",
              "      <td>1412.371885</td>\n",
              "      <td>5.210843</td>\n",
              "      <td>-1.529035</td>\n",
              "      <td>1.422504</td>\n",
              "      <td>0.515638</td>\n",
              "      <td>0.583915</td>\n",
              "      <td>-0.398832</td>\n",
              "      <td>200</td>\n",
              "      <td>1.217663</td>\n",
              "      <td>1.821336</td>\n",
              "      <td>...</td>\n",
              "      <td>1.879230</td>\n",
              "      <td>1.276717e-09</td>\n",
              "      <td>3.958873e-10</td>\n",
              "      <td>2.411036e-10</td>\n",
              "      <td>3.669396e-11</td>\n",
              "      <td>12</td>\n",
              "      <td>5.085240e-10</td>\n",
              "      <td>1.240023e-09</td>\n",
              "      <td>1.439770</td>\n",
              "      <td>3.400361e-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>684 rows × 261 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed64f1f8-a143-42f5-8e34-17990bba8a38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed64f1f8-a143-42f5-8e34-17990bba8a38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed64f1f8-a143-42f5-8e34-17990bba8a38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation\n",
        "Code hieronder is nested cross-validatie toegepast op een k-NN classifier (met verdeling outerloop training:test = 80:20 en verdeling innerloop training:validatie = 80:20)."
      ],
      "metadata": {
        "id": "BIGLMKKeoMm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn import neighbors, metrics\n",
        "import seaborn\n",
        "\n",
        "# Create a X fold stratified CV iterator\n",
        "cv_outer = StratifiedKFold(n_splits=5)\n",
        "results = []\n",
        "best_n_neighbors = []\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_outer.split(features, labels):\n",
        "    \n",
        "\t\t# Split the data properly\n",
        "    data_train_val = features.to_numpy()[validation_index]\n",
        "    label_train_val = labels.to_numpy()[validation_index]\n",
        "   \n",
        "    data_test = features.to_numpy()[test_index]\n",
        "    label_test = labels.to_numpy()[test_index]\n",
        "\n",
        "    # Check the stratification \n",
        "    # print(label_train_val)\n",
        "    \n",
        "    # percent_AD_train = sum(np.char.count(label_train_val,'AD'))\n",
        "    percent_AD_train = (label_train_val == 'AD').sum()/len(label_train_val)*100\n",
        "    percent_CN_train = (label_train_val == 'CN').sum()/len(label_train_val)*100\n",
        "    percent_AD_test = (label_test == 'AD').sum()/len(label_test)*100\n",
        "    percent_CN_test = (label_test == 'CN').sum()/len(label_test)*100\n",
        "    print(f\"{percent_AD_train:.2f}% of the train data are Alzheimer disease samples.\")\n",
        "    print(f\"{percent_CN_train:.2f}% of the train data are control samples.\")\n",
        "    print(f\"{percent_AD_test:.2f}% of the test data are Alzheimer disease samples.\")\n",
        "    print(f\"{percent_CN_test:.2f}% of the test data are control samples.\")\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 26, 2))}\n",
        "    knn = neighbors.KNeighborsClassifier()\n",
        "    cv_inner = StratifiedKFold(n_splits=5)\n",
        "    grid_search = GridSearchCV(knn, parameters, cv=cv_inner, scoring='roc_auc')\n",
        "    grid_search.fit(data_train_val, label_train_val)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "\n",
        "# \t\t# Test the classifier on the test data\n",
        "#     probabilities = clf.predict_proba(data_test)\n",
        "#     scores = probabilities[:, 1]\n",
        "    \n",
        "#     # Get the auc\n",
        "#     auc = metrics.roc_auc_score(label_test, scores)\n",
        "#     results.append({\n",
        "#         'auc': auc,\n",
        "#         'k': clf.n_neighbors,\n",
        "#         'set': 'test'\n",
        "#     })\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_train_val = clf.predict_proba(data_train_val)\n",
        "    scores_train_val = probabilities_train_val[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(label_train_val, scores_train_val)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")"
      ],
      "metadata": {
        "id": "AgRXmCdaox_F",
        "outputId": "2a201fda-be14-435d-e958-f64301394f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60.67% of the train data are Alzheimer disease samples.\n",
            "39.33% of the train data are control samples.\n",
            "60.82% of the test data are Alzheimer disease samples.\n",
            "39.18% of the test data are control samples.\n",
            "Best classifier: k=25\n",
            "60.67% of the train data are Alzheimer disease samples.\n",
            "39.33% of the train data are control samples.\n",
            "60.82% of the test data are Alzheimer disease samples.\n",
            "39.18% of the test data are control samples.\n",
            "Best classifier: k=23\n",
            "60.67% of the train data are Alzheimer disease samples.\n",
            "39.33% of the train data are control samples.\n",
            "60.82% of the test data are Alzheimer disease samples.\n",
            "39.18% of the test data are control samples.\n",
            "Best classifier: k=25\n",
            "60.67% of the train data are Alzheimer disease samples.\n",
            "39.33% of the train data are control samples.\n",
            "60.82% of the test data are Alzheimer disease samples.\n",
            "39.18% of the test data are control samples.\n",
            "Best classifier: k=13\n",
            "60.82% of the train data are Alzheimer disease samples.\n",
            "39.18% of the train data are control samples.\n",
            "60.23% of the test data are Alzheimer disease samples.\n",
            "39.77% of the test data are control samples.\n",
            "Best classifier: k=25\n",
            "The optimal N=25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Feature Selection "
      ],
      "metadata": {
        "id": "22keSkOv408B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import matplotlib.pyplot as plt\n",
        "bestfeatures = SelectKBest(score_func=f_classif, k=261)\n",
        "fit = bestfeatures.fit(data_designset, label_designset)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(data_designset.columns)\n",
        "\n",
        "#concat two dataframes\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "featureScores = featureScores.sort_values('Score')\n",
        "print(featureScores.nlargest(50,'Score'))  #printing 10 best features\n",
        "scores = featureScores['Score'].tonumpy()\n",
        "print(scores)\n",
        "plt.plot(scores)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "aCGpuJGg46OH",
        "outputId": "09c1b0e9-20c4-4f14-a7d7-11807338ad33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Specs       Score\n",
            "1                                   hf_entropy  487.204831\n",
            "2                                  hf_kurtosis  386.354822\n",
            "224                          tf_LBP_std_R3_P12  356.877527\n",
            "8                            hf_quartile_range  356.192050\n",
            "11                                      hf_std  335.410993\n",
            "117                  tf_GLRLM_ShortRunEmphasis  297.952073\n",
            "228                        tf_NGTDM_Complexity  297.678975\n",
            "106                 tf_GLRLM_GrayLevelVariance  287.360495\n",
            "105  tf_GLRLM_GrayLevelNonUniformityNormalized  287.360495\n",
            "119      tf_GLRLM_ShortRunLowGrayLevelEmphasis  275.733263\n",
            "76              phasef_phasesym_entropy_WL3_N5  240.930317\n",
            "140                      tf_Gabor_0.05A0.0skew  222.475894\n",
            "115                     tf_GLRLM_RunPercentage  199.004089\n",
            "229                          tf_NGTDM_Contrast  197.679472\n",
            "108                   tf_GLRLM_LongRunEmphasis  192.793747\n",
            "6                                       hf_min  189.256824\n",
            "79                 phasef_phasesym_mean_WL3_N5  177.336696\n",
            "209                     tf_LBP_kurtosis_R3_P12  174.926772\n",
            "145                      tf_Gabor_0.05A0.79min  174.511082\n",
            "85             phasef_phasesym_skewness_WL3_N5  171.244826\n",
            "156                     tf_Gabor_0.05A2.36mean  166.852643\n",
            "143                      tf_Gabor_0.05A0.79max  166.761154\n",
            "113            tf_GLRLM_RunLengthNonUniformity  166.743800\n",
            "86                  phasef_phasesym_std_WL3_N5  159.682916\n",
            "9                                     hf_range  159.650604\n",
            "78                  phasef_phasesym_max_WL3_N5  157.816105\n",
            "84                phasef_phasesym_range_WL3_N5  157.816105\n",
            "168                      tf_Gabor_0.2A0.79mean  150.594379\n",
            "226                          tf_NGTDM_Busyness  149.248420\n",
            "114  tf_GLRLM_RunLengthNonUniformityNormalized  147.151770\n",
            "161                        tf_Gabor_0.2A0.0max  142.968631\n",
            "142                     tf_Gabor_0.05A0.79kurt  135.568885\n",
            "150                     tf_Gabor_0.05A1.57mean  127.365833\n",
            "165                        tf_Gabor_0.2A0.0std  124.128500\n",
            "148                     tf_Gabor_0.05A1.57kurt  122.408440\n",
            "160                       tf_Gabor_0.2A0.0kurt  119.202860\n",
            "149                      tf_Gabor_0.05A1.57max  117.254766\n",
            "159                      tf_Gabor_0.05A2.36std  113.622373\n",
            "162                       tf_Gabor_0.2A0.0mean  112.447063\n",
            "109      tf_GLRLM_LongRunHighGrayLevelEmphasis  110.794846\n",
            "4                                      hf_mean  109.586442\n",
            "118     tf_GLRLM_ShortRunHighGrayLevelEmphasis  108.463960\n",
            "146                     tf_Gabor_0.05A0.79skew  107.668187\n",
            "163                        tf_Gabor_0.2A0.0min  107.303782\n",
            "77             phasef_phasesym_kurtosis_WL3_N5  103.077621\n",
            "170                      tf_Gabor_0.2A0.79skew  101.490792\n",
            "7                                      hf_peak  100.889490\n",
            "151                      tf_Gabor_0.05A1.57min  100.022414\n",
            "171                       tf_Gabor_0.2A0.79std   99.930737\n",
            "247    vf_Frangi_full_mean_SR(1.0, 10.0)_SS2.0   99.914305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 68  69  80  81 214 217 219] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-a2bbf1aca491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfeatureScores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#printing 10 best features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureScores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtonumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'tonumpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiers\n",
        "## PCA"
      ],
      "metadata": {
        "id": "0W9tsVcxvTKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General Import\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create a PCA which retains n principle components\n",
        "n_pca = 5\n",
        "pca = PCA(n_components=n_pca)\n",
        "\n",
        "# Fit the PCA model, point_data_train should be a 2D numpy array\n",
        "# which has one row per subject and the pointdata as columns where\n",
        "# the columns are x1, y1, z1, x2, y2, z2, ..., xn, yn, zn\n",
        "pca.fit(data_trainset)\n",
        "\n",
        "# Transform data\n",
        "data_trainset_trans = pca.transform(data_trainset)\n"
      ],
      "metadata": {
        "id": "C_vMuvALvpNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "bH8S0aUHMqlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different methods for feature scaling. Decision will be made after usage of PCA\n",
        "# Import modules\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_train = data_designset\n",
        "x_train_stand = x_train.copy()\n",
        "\n",
        "# Robust scaler - based on percentiles. Not influenced by a few number of very large marginal outliers\n",
        "trans = RobustScaler()\n",
        "x_train_robust = trans.fit_transform(x_train)\n",
        "\n",
        "# Standard scaler - removes the mean and scales the data to unit variance\n",
        "scaler = StandardScaler()\n",
        "x_train_scaler = scaler.fit_transform(x_train)\n",
        "\n",
        "# MinMax scaler - rescales data set such that all feature values are in range [0,1]\n",
        "norm = MinMaxScaler().fit(x_train)\n",
        "x_train_norm = norm.transform(x_train)\n"
      ],
      "metadata": {
        "id": "8s6_Mk4Yuq4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}